{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install timm pigeon-jupyter"
      ],
      "metadata": {
        "id": "PkB9SP3V6H3Y"
      },
      "id": "PkB9SP3V6H3Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4167316c-5817-44eb-b6e3-b124a03019ed",
      "metadata": {
        "id": "4167316c-5817-44eb-b6e3-b124a03019ed"
      },
      "source": [
        "# 1. Environment Set Up\n",
        "- Do neccesary imports\n",
        "- Set up where the data is \n",
        "- Create a Labeled Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48c964b0-aeeb-4efa-bdb3-b24bdb2eaf2a",
      "metadata": {
        "id": "48c964b0-aeeb-4efa-bdb3-b24bdb2eaf2a"
      },
      "outputs": [],
      "source": [
        "import torch, sys, os, numpy as np, pandas as pd\n",
        "from tqdm import tqdm\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision\n",
        "from fastai.vision.all import *\n",
        "import timm\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "\n",
        "from skimage import io\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "\n",
        "from pigeon import annotate\n",
        "from IPython import display\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "\n",
        "from fastai.vision.all import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! gdown \"1XE_nUkrtiybUAm2c0yYO-lPJbYyFUcww\""
      ],
      "metadata": {
        "id": "yV1dBpmf6VFx"
      },
      "id": "yV1dBpmf6VFx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip images.zip"
      ],
      "metadata": {
        "id": "xtwlLgQb7EhY"
      },
      "id": "xtwlLgQb7EhY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14691934-87b5-465b-8fec-6620770838da",
      "metadata": {
        "id": "14691934-87b5-465b-8fec-6620770838da"
      },
      "outputs": [],
      "source": [
        "ROOT_DIR = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1(a) Create a Labeled Dataset"
      ],
      "metadata": {
        "id": "Yxv4CsI26lIk"
      },
      "id": "Yxv4CsI26lIk"
    },
    {
      "cell_type": "code",
      "source": [
        "annotations = annotate(\n",
        "  [os.path.join(ROOT_DIR, \"train\", i) for  i in os.listdir(os.path.join(ROOT_DIR, \"train\"))],\n",
        "  options=[],\n",
        "  display_fn=lambda filename: display.display(display.Image(filename))\n",
        ")"
      ],
      "metadata": {
        "id": "CSRqBT6w6o6v"
      },
      "id": "CSRqBT6w6o6v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.DataFrame([(i[0].split(\"/\")[-1], i[1]) for i in annotations], columns=[[\"filename\", \"label\"]])"
      ],
      "metadata": {
        "id": "GpSJUxLj_Pav"
      },
      "id": "GpSJUxLj_Pav",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QtyPuIAO_bbk"
      },
      "id": "QtyPuIAO_bbk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e1f49b2e-1b79-4bbd-96bf-528564957a50",
      "metadata": {
        "id": "e1f49b2e-1b79-4bbd-96bf-528564957a50"
      },
      "source": [
        "# 2. Specify Additional Useful Functions (Utils)\n",
        "- ArcFace Loss\n",
        "- Transformation function to convert images to RGB"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ac16bc3-1eb6-4fa1-95c0-6af91a9bbe60",
      "metadata": {
        "id": "7ac16bc3-1eb6-4fa1-95c0-6af91a9bbe60"
      },
      "source": [
        "https://www.kaggle.com/code/slawekbiel/arcface-explained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ed95193-291b-46ba-b29c-d23c7ae97126",
      "metadata": {
        "id": "2ed95193-291b-46ba-b29c-d23c7ae97126"
      },
      "outputs": [],
      "source": [
        "class ArcMarginProduct(nn.Module):\n",
        "    r\"\"\"Implement of large margin arc distance: :\n",
        "        Args:\n",
        "            in_features: size of each input sample\n",
        "            out_features: size of each output sample\n",
        "            s: norm of input feature\n",
        "            m: margin\n",
        "            cos(theta + m)\n",
        "        \"\"\"\n",
        "    def __init__(self, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0, final_loss = FocalLossFlat()):\n",
        "        super(ArcMarginProduct, self).__init__()\n",
        "        self.s = s\n",
        "        self.m = m\n",
        "        self.ls_eps = ls_eps  # label smoothing\n",
        "        self.easy_margin = easy_margin\n",
        "        self.final_loss = final_loss\n",
        "        self.cos_m = math.cos(m)\n",
        "        self.sin_m = math.sin(m)\n",
        "        self.th = math.cos(math.pi - m)\n",
        "        self.mm = math.sin(math.pi - m) * m\n",
        "\n",
        "    def forward(self, cosine, label):\n",
        "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
        "        sine = torch.sqrt(1.0 - torch.pow(cosine,2)).to(cosine.dtype) #needed for to_fp16()\n",
        "        phi = cosine * self.cos_m - sine * self.sin_m\n",
        "        if self.easy_margin:\n",
        "            phi = torch.where(cosine > 0, phi, cosine)\n",
        "        else:\n",
        "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
        "        # --------------------------- convert label to one-hot ---------------------------\n",
        "        one_hot = torch.zeros(cosine.size(), device=CFG.device)\n",
        "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
        "        if self.ls_eps > 0:\n",
        "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
        "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
        "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
        "        output *= self.s\n",
        "\n",
        "        return self.final_loss(output, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86ce7190-5e35-4051-a5f2-8b58b9fb0ab8",
      "metadata": {
        "id": "86ce7190-5e35-4051-a5f2-8b58b9fb0ab8"
      },
      "outputs": [],
      "source": [
        "def arcface_loss(cosine, targ, m=.4):\n",
        "    # this prevents nan when a value slightly crosses 1.0 due to numerical error\n",
        "    cosine = cosine.clip(-1+1e-7, 1-1e-7) \n",
        "    # Step 3:\n",
        "    arcosine = cosine.arccos()\n",
        "    # Step 4:\n",
        "    one_hot = torch.zeros(cosine.size(), device='cuda')\n",
        "    one_hot.scatter_(1, targ.view(-1, 1).long(), 1)\n",
        "    arcosine += one_hot * m\n",
        "    # Step 5:\n",
        "    cosine2 = arcosine.cos()\n",
        "    # Step 6:\n",
        "    return FocalLossFlat()(cosine2, targ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d63342c9-681b-415f-8ff5-dc10d27dbbbf",
      "metadata": {
        "id": "d63342c9-681b-415f-8ff5-dc10d27dbbbf"
      },
      "outputs": [],
      "source": [
        "class CosineClassifier(nn.Module):\n",
        "    def __init__(self, emb_size, output_classes):\n",
        "        super(CosineClassifier, self).__init__()\n",
        "        self.W = nn.Parameter(torch.Tensor(emb_size, output_classes))\n",
        "        nn.init.kaiming_uniform_(self.W)\n",
        "    def forward(self, x):\n",
        "        # Step 1:\n",
        "        x_norm = F.normalize(x)\n",
        "        W_norm = F.normalize(self.W, dim=0)\n",
        "        # Step 2:\n",
        "        return x_norm @ W_norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87a3eb28-ea94-41bd-9d3d-f90067d81661",
      "metadata": {
        "id": "87a3eb28-ea94-41bd-9d3d-f90067d81661"
      },
      "outputs": [],
      "source": [
        "def convert_to_color(img: PILImage):\n",
        "    np_img = np.array(img)\n",
        "    if np_img.ndim <3:\n",
        "        np_img = np.repeat(np_img[:, :, np.newaxis], 3, axis=2)\n",
        "    return PILImage.create(np_img)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a3925e4-d72f-4043-8c21-e91329f918cc",
      "metadata": {
        "id": "1a3925e4-d72f-4043-8c21-e91329f918cc"
      },
      "source": [
        "# 2. Set Up Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12e969b0-a06c-4198-85a2-2c18a6e989bc",
      "metadata": {
        "id": "12e969b0-a06c-4198-85a2-2c18a6e989bc"
      },
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    # Data\n",
        "    batch_size= 16\n",
        "    img_size = 384\n",
        "    shuffle=True\n",
        "    label_col = \"label\"\n",
        "    fn_col = \"filename\"\n",
        "    data_path = os.path.join(ROOT_DIR, \"train\")\n",
        "    \n",
        "    # Model\n",
        "    model_name = 'resnext101_64x4d'\n",
        "    model_dir = \"fastai_models\"\n",
        "    pretrained = True\n",
        "    num_classes=2\n",
        "    \n",
        "    # Training\n",
        "    epochs = 15\n",
        "    freeze_epochs=3\n",
        "    loss_func = BaseLoss(ArcMarginProduct)\n",
        "    callbacks = [\n",
        "        EarlyStoppingCallback(monitor=\"valid_loss\", min_delta=0.001, patience=3)\n",
        "    ]\n",
        "    metrics = [\n",
        "        accuracy_multi, F1ScoreMulti\n",
        "    ]\n",
        "    num_folds = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b48f6618-9581-4969-ae84-703b3f94587e",
      "metadata": {
        "id": "b48f6618-9581-4969-ae84-703b3f94587e"
      },
      "source": [
        "# 3. Create Data Loaders\n",
        "- create and check any custom transforms\n",
        "- specify image augmentation\n",
        "- add in any validation splits"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train, val = train_test_split(labels_df)\n",
        "train[\"valid\"] = 0\n",
        "val[\"valid\"] = 1\n",
        "labels_df = pd.concat([train, val])"
      ],
      "metadata": {
        "id": "vm8-vRFtF0Ge"
      },
      "id": "vm8-vRFtF0Ge",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdcd1091-1041-4880-9f9c-65e3408a04d8",
      "metadata": {
        "id": "bdcd1091-1041-4880-9f9c-65e3408a04d8"
      },
      "outputs": [],
      "source": [
        "dls = ImageDataLoaders.from_df(labels_df, num_workers=0,\n",
        "                                   label_col= CFG.label_col,\n",
        "                                   fn_col = CFG.fn_col,\n",
        "                                   path = CFG.data_path,\n",
        "                                   bs = CFG.batch_size,\n",
        "                                   valid_col = \"valid\",\n",
        "                                   shuffle = CFG.shuffle,\n",
        "                                   device = CFG.device,\n",
        "                                   item_tfms=[convert_to_color, Resize(460)],\n",
        "                                   batch_tfms=aug_transforms(size=CFG.img_size)\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07833471-4e03-4104-8fd2-8ae6301e7d01",
      "metadata": {
        "id": "07833471-4e03-4104-8fd2-8ae6301e7d01"
      },
      "outputs": [],
      "source": [
        "dls.show_batch()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daa0fddb-c814-422d-b100-45e3ae233662",
      "metadata": {
        "id": "daa0fddb-c814-422d-b100-45e3ae233662"
      },
      "source": [
        "# 4. Train the Model\n",
        "- Create the model\n",
        "- Create a FastAI Learner\n",
        "- Find a good learning rate for model\n",
        "- Fit a model across different folds of the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f95badb-e69c-41a6-baf9-4877485d795c",
      "metadata": {
        "id": "7f95badb-e69c-41a6-baf9-4877485d795c"
      },
      "outputs": [],
      "source": [
        "class NN_Model(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_classes,\n",
        "                 model_name=CFG.model_name,\n",
        "                 pretrained=True):\n",
        "        \n",
        "        super(NN_Model, self).__init__()\n",
        "\n",
        "        model = timm.create_model(model_name, pretrained=pretrained)\n",
        "        final_in_features = list(model.children())[-1].in_features\n",
        "        self.backbone = nn.Sequential(*list(model.children())[:-1])\n",
        "        self.classifier = CosineClassifier(final_in_features, n_classes)\n",
        "        #self.classifier = nn.Linear(final_in_features, n_classes, bias = True)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        feature = self.backbone(x)\n",
        "        return self.classifier(feature)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6ab2f94-f639-45d8-9fa3-2bb9566e1f5a",
      "metadata": {
        "id": "a6ab2f94-f639-45d8-9fa3-2bb9566e1f5a"
      },
      "outputs": [],
      "source": [
        "model = NN_Model(CFG.num_classes, model_name=CFG.model_name, pretrained=CFG.pretrained).to(CFG.device)\n",
        "learn = Learner(dls, model, loss_func=CFG.loss_func, metrics=accuracy, cbs = CFG.callbacks,\n",
        "                path=CFG.model_path, model_dir=CFG.model_dir).to_fp16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3489fafc-ae66-4fdc-8ed2-39cd8bfe1bd8",
      "metadata": {
        "id": "3489fafc-ae66-4fdc-8ed2-39cd8bfe1bd8"
      },
      "outputs": [],
      "source": [
        "learn.lr_find()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9f2d283-9875-4575-80eb-5924b009e632",
      "metadata": {
        "id": "d9f2d283-9875-4575-80eb-5924b009e632"
      },
      "outputs": [],
      "source": [
        "learn.fine_tune(epochs=CFG.epochs, base_lr=1e-3, freeze_epochs=CFG.freeze_epochs, \n",
        "                    cbs=[SaveModelCallback(monitor=\"valid_loss\", min_delta=0.001, fname=CFG.model_name+\"_trained\")])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "657c70e8-03c5-4a7e-9567-74e44b4dbd3c",
      "metadata": {
        "id": "657c70e8-03c5-4a7e-9567-74e44b4dbd3c"
      },
      "source": [
        "### Check out predictions and losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9609d5cd-3b28-4695-b38e-5a4119bc0b50",
      "metadata": {
        "id": "9609d5cd-3b28-4695-b38e-5a4119bc0b50"
      },
      "outputs": [],
      "source": [
        "learn.load(os.path.join(CFG.model_name+\"_trained\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e99efa-fdbd-4cab-915a-a70fd5dc3549",
      "metadata": {
        "id": "f2e99efa-fdbd-4cab-915a-a70fd5dc3549"
      },
      "outputs": [],
      "source": [
        "learn.loss_func = FocalLossFlat()\n",
        "learn.show_results()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f7ac106-2b7f-4bbc-ac68-ea02c6c085f9",
      "metadata": {
        "id": "3f7ac106-2b7f-4bbc-ac68-ea02c6c085f9"
      },
      "outputs": [],
      "source": [
        "interp = Interpretation.from_learner(learn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0493718-c459-44a2-acc9-b79308f42040",
      "metadata": {
        "id": "d0493718-c459-44a2-acc9-b79308f42040"
      },
      "outputs": [],
      "source": [
        "interp.plot_top_losses(9, figsize=(15,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0475ac7e-4a93-4a96-8bb1-6b57712c91d9",
      "metadata": {
        "id": "0475ac7e-4a93-4a96-8bb1-6b57712c91d9"
      },
      "source": [
        "# 5. Perform Inference\n",
        "- Need to have the DataLoader and model already defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6f6ec1-d1de-40f0-8a0c-270ef9b5cf54",
      "metadata": {
        "id": "5c6f6ec1-d1de-40f0-8a0c-270ef9b5cf54"
      },
      "outputs": [],
      "source": [
        "img_files = [os.path.join(ROOT_DIR, \"test\", i) for  i in os.listdir(os.path.join(ROOT_DIR, \"test\"))][:1000]\n",
        "test_dl = learn.dls.test_dl(img_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7647967f-29bd-4517-9824-2446947e8525",
      "metadata": {
        "collapsed": true,
        "id": "7647967f-29bd-4517-9824-2446947e8525"
      },
      "outputs": [],
      "source": [
        "preds, _ = learn.get_preds(dl=test_dl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12672722-e61d-48f0-9c14-1d0fe62fe13c",
      "metadata": {
        "id": "12672722-e61d-48f0-9c14-1d0fe62fe13c"
      },
      "outputs": [],
      "source": [
        "preds = preds.to('cpu').numpy().argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_grid(images, ncols=None, cmap='gray'):\n",
        "    '''Plot a grid of images'''\n",
        "    if not ncols:\n",
        "        factors = [i for i in range(1, len(images)+1) if len(images) % i == 0]\n",
        "        ncols = factors[len(factors) // 2] if len(factors) else len(images) // 4 + 1\n",
        "    nrows = int(len(images) / ncols) + int(len(images) % ncols)\n",
        "    imgs = [images[i] if len(images) > i else None for i in range(nrows * ncols)]\n",
        "    f, axes = plt.subplots(nrows, ncols, figsize=(3*ncols, 2*nrows))\n",
        "    axes = axes.flatten()[:len(imgs)]\n",
        "    for img, ax in zip(imgs, axes.flatten()): \n",
        "        if np.any(img):\n",
        "            if len(img.shape) > 2 and img.shape[2] == 1:\n",
        "                img = img.squeeze()\n",
        "            ax.imshow(img, cmap=cmap)"
      ],
      "metadata": {
        "id": "R76ZeSWLZ_ZK"
      },
      "id": "R76ZeSWLZ_ZK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mil_images = [mpimg.imread(img_files[i]) for i in np.where(preds==0)[0]][:10]\n",
        "\n",
        "plot_image_grid(mil_images)"
      ],
      "metadata": {
        "id": "bvT-c_NwWYhX"
      },
      "id": "bvT-c_NwWYhX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "civ_images = [mpimg.imread(img_files[i]) for i in np.where(preds==1)[0]][:10]\n",
        "\n",
        "plot_image_grid(civ_images)"
      ],
      "metadata": {
        "id": "iTMhf7Q-Wwfy"
      },
      "id": "iTMhf7Q-Wwfy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5utPI0OeYyhV"
      },
      "id": "5utPI0OeYyhV",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}